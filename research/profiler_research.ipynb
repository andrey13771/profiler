{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import accuracy_score as accuracy, precision_score as precision, recall_score as recall, roc_auc_score as auc, confusion_matrix as confm\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://fhaqftqhkzrvnq:b76a214722d9525e3647b40f44a6051e915270788d40d531aecfbdf4d102c435@ec2-3-221-243-122.compute-1.amazonaws.com:5432/dee2cchssk4u3u')\n",
    "df = pd.read_sql_table('tab_info', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://fhaqftqhkzrvnq:b76a214722d9525e3647b40f44a6051e915270788d40d531aecfbdf4d102c435@ec2-3-221-243-122.compute-1.amazonaws.com:5432/dee2cchssk4u3u')\n",
    "df = pd.read_sql_table('keyboard_timing', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>keypress</th>\n",
       "      <th>keyup</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'KeyP', 'ctrl': False,...</td>\n",
       "      <td>[{'code': 'ShiftLeft', 'timestamp': 11315.9900...</td>\n",
       "      <td>2021-04-16 12:37:38.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'Space', 'ctrl': False...</td>\n",
       "      <td>[{'code': 'Space', 'timestamp': 38889.98999999...</td>\n",
       "      <td>2021-04-16 12:38:21.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'Digit0', 'ctrl': Fals...</td>\n",
       "      <td>[{'code': 'ArrowRight', 'timestamp': 25940.814...</td>\n",
       "      <td>2021-04-16 12:52:17.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'Digit0', 'ctrl': Fals...</td>\n",
       "      <td>[{'code': 'ArrowRight', 'timestamp': 36934.019...</td>\n",
       "      <td>2021-04-16 13:01:09.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'KeyS', 'ctrl': False,...</td>\n",
       "      <td>[{'code': 'KeyS', 'timestamp': 304650.77000000...</td>\n",
       "      <td>2021-04-16 15:00:17.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'Digit4', 'ctrl': Fals...</td>\n",
       "      <td>[{'code': 'Backspace', 'timestamp': 20023727.5...</td>\n",
       "      <td>2021-04-27 18:13:32.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'KeyH', 'ctrl': False,...</td>\n",
       "      <td>[{'code': 'KeyH', 'timestamp': 20119890.565}, ...</td>\n",
       "      <td>2021-04-27 18:14:20.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'Minus', 'ctrl': False...</td>\n",
       "      <td>[{'code': 'Minus', 'timestamp': 20168747.565},...</td>\n",
       "      <td>2021-04-27 18:23:18.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'BracketLeft', 'ctrl':...</td>\n",
       "      <td>[{'code': 'BracketLeft', 'timestamp': 20706426...</td>\n",
       "      <td>2021-04-27 18:36:33.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>383</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'alt': False, 'code': 'Period', 'ctrl': Fals...</td>\n",
       "      <td>[{'code': 'Period', 'timestamp': 21501490.5650...</td>\n",
       "      <td>2021-04-27 18:44:49.194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  user_id                                           keypress  \\\n",
       "0      6        1  [{'alt': False, 'code': 'KeyP', 'ctrl': False,...   \n",
       "1      7        1  [{'alt': False, 'code': 'Space', 'ctrl': False...   \n",
       "2      8        1  [{'alt': False, 'code': 'Digit0', 'ctrl': Fals...   \n",
       "10     9        1  [{'alt': False, 'code': 'Digit0', 'ctrl': Fals...   \n",
       "3     10        1  [{'alt': False, 'code': 'KeyS', 'ctrl': False,...   \n",
       "..   ...      ...                                                ...   \n",
       "371  379        1  [{'alt': False, 'code': 'Digit4', 'ctrl': Fals...   \n",
       "374  380        1  [{'alt': False, 'code': 'KeyH', 'ctrl': False,...   \n",
       "376  381        1  [{'alt': False, 'code': 'Minus', 'ctrl': False...   \n",
       "377  382        1  [{'alt': False, 'code': 'BracketLeft', 'ctrl':...   \n",
       "375  383        1  [{'alt': False, 'code': 'Period', 'ctrl': Fals...   \n",
       "\n",
       "                                                 keyup               timestamp  \n",
       "0    [{'code': 'ShiftLeft', 'timestamp': 11315.9900... 2021-04-16 12:37:38.432  \n",
       "1    [{'code': 'Space', 'timestamp': 38889.98999999... 2021-04-16 12:38:21.263  \n",
       "2    [{'code': 'ArrowRight', 'timestamp': 25940.814... 2021-04-16 12:52:17.503  \n",
       "10   [{'code': 'ArrowRight', 'timestamp': 36934.019... 2021-04-16 13:01:09.166  \n",
       "3    [{'code': 'KeyS', 'timestamp': 304650.77000000... 2021-04-16 15:00:17.685  \n",
       "..                                                 ...                     ...  \n",
       "371  [{'code': 'Backspace', 'timestamp': 20023727.5... 2021-04-27 18:13:32.005  \n",
       "374  [{'code': 'KeyH', 'timestamp': 20119890.565}, ... 2021-04-27 18:14:20.852  \n",
       "376  [{'code': 'Minus', 'timestamp': 20168747.565},... 2021-04-27 18:23:18.547  \n",
       "377  [{'code': 'BracketLeft', 'timestamp': 20706426... 2021-04-27 18:36:33.573  \n",
       "375  [{'code': 'Period', 'timestamp': 21501490.5650... 2021-04-27 18:44:49.194  \n",
       "\n",
       "[378 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_kb(keypress, keyup):\n",
    "    hold = []\n",
    "    interkey = []\n",
    "    for kp, ku in zip(keypress, keyup):\n",
    "        kpc = kp.copy()\n",
    "        kuc1 = ku.copy()\n",
    "        kuc2 = []\n",
    "        for i in kpc:\n",
    "            rem1 = []\n",
    "            for j in range(len(kuc1)):\n",
    "                if i['code'] == kuc1[j]['code']:\n",
    "                    delay = kuc1[j]['timestamp'] - i['timestamp']\n",
    "                    rem1.append(j)\n",
    "                    if delay > 0:\n",
    "                        hold.append([i['code'], delay, i['ctrl'], i['shift'], i['alt'], i['meta']])\n",
    "                        if kuc1[j] not in kuc2:\n",
    "                            kuc2.append(kuc1[j])\n",
    "                        break\n",
    "            kuc1 = np.delete(kuc1, rem1)\n",
    "        for i in range(1, len(kpc)):\n",
    "            rem1 = []\n",
    "            for j in range(len(kuc2)):\n",
    "                if kpc[i - 1]['code'] == kuc2[j]['code']:\n",
    "                    rem1.append(j)\n",
    "                    delay = kpc[i]['timestamp'] - kuc2[j]['timestamp']\n",
    "                    interkey.append([kpc[i - 1]['code'] + kpc[i]['code'], delay])\n",
    "                    break\n",
    "            kuc2 = np.delete(kuc2, rem1)\n",
    "    hold = pd.DataFrame(hold, columns=['key', 'delay', 'ctrl', 'shift', 'alt', 'meta'])\n",
    "    interkey = pd.DataFrame(interkey, columns=['key', 'delay'])\n",
    "#     interkey = interkey[interkey.delay < 5000]\n",
    "    interkey = interkey[interkey.delay < interkey.delay.quantile(0.75)]\n",
    "    return hold, interkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_kb(keypress, keyup):\n",
    "    hold = []\n",
    "    interkey = []\n",
    "    both = []\n",
    "    for kp, ku in zip(keypress, keyup):\n",
    "        kpc = kp.copy()\n",
    "        kuc1 = ku.copy()\n",
    "        kuc2 = []\n",
    "        for i in kpc:\n",
    "            rem1 = []\n",
    "            for j in range(len(kuc1)):\n",
    "                if i['code'] == kuc1[j]['code']:\n",
    "                    delay = kuc1[j]['timestamp'] - i['timestamp']\n",
    "                    rem1.append(j)\n",
    "                    if delay > 0:\n",
    "                        hold.append([i['code'], delay, i['ctrl'], i['shift'], i['alt'], i['meta']])\n",
    "                        if kuc1[j] not in kuc2:\n",
    "                            kuc2.append(kuc1[j])\n",
    "                        break\n",
    "            kuc1 = np.delete(kuc1, rem1)\n",
    "        for i in range(1, len(kpc)):\n",
    "            rem1 = []\n",
    "            for j in range(len(kuc2)):\n",
    "                if kpc[i - 1]['code'] == kuc2[j]['code']:\n",
    "                    rem1.append(j)\n",
    "                    delay1 = kuc2[j]['timestamp'] - kpc[i - 1]['timestamp']\n",
    "                    delay2 = kpc[i]['timestamp'] - kuc2[j]['timestamp']\n",
    "                    interkey.append([kpc[i - 1]['code'] + kpc[i]['code'], delay2])\n",
    "                    both.append([kpc[i - 1]['code'], kpc[i]['code'], delay1, delay2, kpc[i - 1]['shift']])\n",
    "                    break\n",
    "            kuc2 = np.delete(kuc2, rem1)\n",
    "    hold = pd.DataFrame(hold, columns=['key', 'delay', 'ctrl', 'shift', 'alt', 'meta'])\n",
    "    interkey = pd.DataFrame(interkey, columns=['key', 'delay'])\n",
    "#     interkey = interkey[interkey.delay < 5000]\n",
    "    interkey = interkey[interkey.delay < interkey.delay.quantile(0.75)]\n",
    "    both = pd.DataFrame(both, columns=['key1', 'key2', 'hold', 'interkey', 'shift'])\n",
    "#     both = both[both.interkey < 5000]\n",
    "    both = both[both.interkey < both.interkey.quantile(0.75)]\n",
    "    return hold, interkey, both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.user_id == 1]\n",
    "df2 = df[df.user_id == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold1, interkey1, both1 = process_kb(df1.keypress, df1.keyup)\n",
    "hold2, interkey2, both2 = process_kb(df2.keypress, df2.keyup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = pd.concat([hold1, hold2])\n",
    "hold = pd.get_dummies(hold, columns=['key'])\n",
    "hold1 = hold.iloc[:13166]\n",
    "hold2 = hold.iloc[13166:]\n",
    "hold1 = hold1.drop(columns=['ctrl', 'shift', 'alt', 'meta', 'code', 'true'])\n",
    "hold2 = hold2.drop(columns=['ctrl', 'shift', 'alt', 'meta', 'code', 'true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = pd.concat([both1, both2])\n",
    "both = pd.get_dummies(both, columns=['key1', 'key2'])\n",
    "both1 = both.iloc[:9641]\n",
    "both2 = both.iloc[9641:]\n",
    "both1 = both1.drop(columns=['shift'])\n",
    "both2 = both2.drop(columns=['shift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys1 = set(both1.key1)\n",
    "keys2 = set(both1.key2)\n",
    "keys3 = set(both2.key1)\n",
    "keys4 = set(both2.key2)\n",
    "keys = keys1 | keys2 | keys3 | keys4\n",
    "keys = dict(zip(keys, range(len(keys))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "both1.key1 = both1.key1.map(keys)\n",
    "both1.key2 = both1.key2.map(keys)\n",
    "both2.key1 = both2.key1.map(keys)\n",
    "both2.key2 = both2.key2.map(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "both1['shift'] = both1['shift'].apply(int)\n",
    "both2['shift'] = both2['shift'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "both1 = pd.concat([hold1, interkey1])\n",
    "both2 = pd.concat([hold2, interkey2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold1['code'] = pd.factorize(hold1.key)[0]\n",
    "hold2['code'] = pd.factorize(hold2.key)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "interkey1['code'] = pd.factorize(interkey1['key'])[0]\n",
    "interkey2['code'] = pd.factorize(interkey2['key'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "both1['code'] = pd.factorize(both1['key'])[0]\n",
    "both2['code'] = pd.factorize(both2['key'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold1['shift'] = hold1['shift'].apply(int)\n",
    "hold2['shift'] = hold2['shift'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>delay</th>\n",
       "      <th>ctrl</th>\n",
       "      <th>shift</th>\n",
       "      <th>alt</th>\n",
       "      <th>meta</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11479</td>\n",
       "      <td>11479.00000</td>\n",
       "      <td>11479</td>\n",
       "      <td>11479</td>\n",
       "      <td>11479</td>\n",
       "      <td>11479</td>\n",
       "      <td>11479.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Space</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11474</td>\n",
       "      <td>10451</td>\n",
       "      <td>11479</td>\n",
       "      <td>11479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>109.45466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.13425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.62076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.50451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>132.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>319.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          key       delay   ctrl  shift    alt   meta        code\n",
       "count   11479 11479.00000  11479  11479  11479  11479 11479.00000\n",
       "unique     50         NaN      2      2      1      1         NaN\n",
       "top     Space         NaN  False  False  False  False         NaN\n",
       "freq      844         NaN  11474  10451  11479  11479         NaN\n",
       "mean      NaN   109.45466    NaN    NaN    NaN    NaN    19.13425\n",
       "std       NaN    34.62076    NaN    NaN    NaN    NaN    13.50451\n",
       "min       NaN    11.00000    NaN    NaN    NaN    NaN     0.00000\n",
       "25%       NaN    88.00000    NaN    NaN    NaN    NaN     7.00000\n",
       "50%       NaN   108.00000    NaN    NaN    NaN    NaN    14.00000\n",
       "75%       NaN   132.00000    NaN    NaN    NaN    NaN    32.00000\n",
       "max       NaN   319.00000    NaN    NaN    NaN    NaN    49.00000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>delay</th>\n",
       "      <th>ctrl</th>\n",
       "      <th>shift</th>\n",
       "      <th>alt</th>\n",
       "      <th>meta</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2067</td>\n",
       "      <td>2067.00000</td>\n",
       "      <td>2067</td>\n",
       "      <td>2067</td>\n",
       "      <td>2067</td>\n",
       "      <td>2067</td>\n",
       "      <td>2067.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Space</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2067</td>\n",
       "      <td>1944</td>\n",
       "      <td>2067</td>\n",
       "      <td>2067</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94.44097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.60232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.70347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.72962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>47.73500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>79.80500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>88.86500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.60500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>245.32000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          key      delay   ctrl  shift    alt   meta       code\n",
       "count    2067 2067.00000   2067   2067   2067   2067 2067.00000\n",
       "unique     42        NaN      1      2      1      1        NaN\n",
       "top     Space        NaN  False  False  False  False        NaN\n",
       "freq      330        NaN   2067   1944   2067   2067        NaN\n",
       "mean      NaN   94.44097    NaN    NaN    NaN    NaN   14.60232\n",
       "std       NaN   22.70347    NaN    NaN    NaN    NaN    9.72962\n",
       "min       NaN   47.73500    NaN    NaN    NaN    NaN    0.00000\n",
       "25%       NaN   79.80500    NaN    NaN    NaN    NaN    6.00000\n",
       "50%       NaN   88.86500    NaN    NaN    NaN    NaN   12.00000\n",
       "75%       NaN   99.60500    NaN    NaN    NaN    NaN   24.00000\n",
       "max       NaN  245.32000    NaN    NaN    NaN    NaN   41.00000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>delay</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8397</td>\n",
       "      <td>8397.00000</td>\n",
       "      <td>8397.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CommaSpace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>85.96642</td>\n",
       "      <td>234.50280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>142.53161</td>\n",
       "      <td>181.10775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-253.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.00000</td>\n",
       "      <td>109.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>167.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>315.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>506.00000</td>\n",
       "      <td>788.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               key      delay       code\n",
       "count         8397 8397.00000 8397.00000\n",
       "unique         789        NaN        NaN\n",
       "top     CommaSpace        NaN        NaN\n",
       "freq           219        NaN        NaN\n",
       "mean           NaN   85.96642  234.50280\n",
       "std            NaN  142.53161  181.10775\n",
       "min            NaN -253.00000    0.00000\n",
       "25%            NaN  -22.00000  109.00000\n",
       "50%            NaN   55.00000  167.00000\n",
       "75%            NaN  154.00000  315.00000\n",
       "max            NaN  506.00000  788.00000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interkey1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>delay</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SlashSpace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>133.31183</td>\n",
       "      <td>104.24267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>109.90925</td>\n",
       "      <td>77.10268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-100.86000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>71.87000</td>\n",
       "      <td>45.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>131.24750</td>\n",
       "      <td>88.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.53875</td>\n",
       "      <td>149.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>384.29000</td>\n",
       "      <td>316.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               key      delay       code\n",
       "count         1500 1500.00000 1500.00000\n",
       "unique         317        NaN        NaN\n",
       "top     SlashSpace        NaN        NaN\n",
       "freq            39        NaN        NaN\n",
       "mean           NaN  133.31183  104.24267\n",
       "std            NaN  109.90925   77.10268\n",
       "min            NaN -100.86000    0.00000\n",
       "25%            NaN   71.87000   45.00000\n",
       "50%            NaN  131.24750   88.00000\n",
       "75%            NaN  204.53875  149.00000\n",
       "max            NaN  384.29000  316.00000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interkey2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lof  iforest     svm\n",
      "accuracy  0.93384  0.75282 0.70134\n",
      "precision 0.99828  0.89655 0.71369\n",
      "recall    0.88345  0.63174 0.77980\n",
      "auc       0.99444  0.74681 0.59040\n",
      "[[2063    4]\n",
      " [ 307 2327]] \n",
      "\n",
      "[[1875  192]\n",
      " [ 970 1664]] \n",
      "\n",
      "[[1243  824]\n",
      " [ 580 2054]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hold_train, hold_test = train_test_split(hold1.copy(), test_size=0.2, random_state=42)\n",
    "hold_test['true'] = 1\n",
    "hold2['true'] = -1\n",
    "hold_test = pd.concat([hold_test, hold2])\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.3, n_neighbors=6)\n",
    "iforest = IsolationForest(random_state=42, contamination=0.38)\n",
    "svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = hold_test.true\n",
    "\n",
    "X_train = hold_train[['delay']]\n",
    "X_test = hold_test[['delay']]\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lof  iforest     svm\n",
      "accuracy  0.93147  0.62321 0.70400\n",
      "precision 0.93977  0.68357 0.77597\n",
      "recall    0.93831  0.61483 0.66615\n",
      "auc       0.95505  0.66403 0.74025\n",
      "[[1384  116]\n",
      " [ 119 1810]] \n",
      "\n",
      "[[ 951  549]\n",
      " [ 743 1186]] \n",
      "\n",
      "[[1129  371]\n",
      " [ 644 1285]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "interkey_train, interkey_test = train_test_split(interkey1.copy(), test_size=0.2, random_state=42)\n",
    "interkey_test['true'] = 1\n",
    "interkey2['true'] = -1\n",
    "interkey_test = pd.concat([interkey_test, interkey2])\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.2, n_neighbors=1)\n",
    "iforest = IsolationForest(random_state=42, contamination=0.38)\n",
    "svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = interkey_test.true\n",
    "\n",
    "X_train = interkey_train[['delay']]\n",
    "X_test = interkey_test[['delay']]\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hold</th>\n",
       "      <th>interkey</th>\n",
       "      <th>key1_Backquote</th>\n",
       "      <th>key1_Backslash</th>\n",
       "      <th>key1_BracketLeft</th>\n",
       "      <th>key1_BracketRight</th>\n",
       "      <th>key1_Comma</th>\n",
       "      <th>key1_Digit0</th>\n",
       "      <th>key1_Digit1</th>\n",
       "      <th>key1_Digit2</th>\n",
       "      <th>...</th>\n",
       "      <th>key2_KeyW</th>\n",
       "      <th>key2_KeyX</th>\n",
       "      <th>key2_KeyY</th>\n",
       "      <th>key2_KeyZ</th>\n",
       "      <th>key2_Minus</th>\n",
       "      <th>key2_Period</th>\n",
       "      <th>key2_Quote</th>\n",
       "      <th>key2_Semicolon</th>\n",
       "      <th>key2_Slash</th>\n",
       "      <th>key2_Space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "      <td>9641.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.02552</td>\n",
       "      <td>86.31138</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00280</td>\n",
       "      <td>0.01577</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.02614</td>\n",
       "      <td>0.01234</td>\n",
       "      <td>0.00819</td>\n",
       "      <td>0.00477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.00425</td>\n",
       "      <td>0.01805</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.01753</td>\n",
       "      <td>0.02323</td>\n",
       "      <td>0.00892</td>\n",
       "      <td>0.00311</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.07748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.02666</td>\n",
       "      <td>142.94229</td>\n",
       "      <td>0.01018</td>\n",
       "      <td>0.05285</td>\n",
       "      <td>0.12458</td>\n",
       "      <td>0.05186</td>\n",
       "      <td>0.15955</td>\n",
       "      <td>0.11042</td>\n",
       "      <td>0.09015</td>\n",
       "      <td>0.06891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04983</td>\n",
       "      <td>0.06508</td>\n",
       "      <td>0.13313</td>\n",
       "      <td>0.04435</td>\n",
       "      <td>0.13124</td>\n",
       "      <td>0.15065</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.05570</td>\n",
       "      <td>0.02494</td>\n",
       "      <td>0.26737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.00000</td>\n",
       "      <td>-253.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.00000</td>\n",
       "      <td>-22.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>109.00000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>132.00000</td>\n",
       "      <td>154.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>344.00000</td>\n",
       "      <td>516.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hold   interkey  key1_Backquote  key1_Backslash  key1_BracketLeft  \\\n",
       "count 9641.00000 9641.00000      9641.00000      9641.00000        9641.00000   \n",
       "mean   111.02552   86.31138         0.00010         0.00280           0.01577   \n",
       "std     36.02666  142.94229         0.01018         0.05285           0.12458   \n",
       "min     11.00000 -253.00000         0.00000         0.00000           0.00000   \n",
       "25%     88.00000  -22.00000         0.00000         0.00000           0.00000   \n",
       "50%    109.00000   55.00000         0.00000         0.00000           0.00000   \n",
       "75%    132.00000  154.00000         0.00000         0.00000           0.00000   \n",
       "max    344.00000  516.00000         1.00000         1.00000           1.00000   \n",
       "\n",
       "       key1_BracketRight  key1_Comma  key1_Digit0  key1_Digit1  key1_Digit2  \\\n",
       "count         9641.00000  9641.00000   9641.00000   9641.00000   9641.00000   \n",
       "mean             0.00270     0.02614      0.01234      0.00819      0.00477   \n",
       "std              0.05186     0.15955      0.11042      0.09015      0.06891   \n",
       "min              0.00000     0.00000      0.00000      0.00000      0.00000   \n",
       "25%              0.00000     0.00000      0.00000      0.00000      0.00000   \n",
       "50%              0.00000     0.00000      0.00000      0.00000      0.00000   \n",
       "75%              0.00000     0.00000      0.00000      0.00000      0.00000   \n",
       "max              1.00000     1.00000      1.00000      1.00000      1.00000   \n",
       "\n",
       "       ...  key2_KeyW  key2_KeyX  key2_KeyY  key2_KeyZ  key2_Minus  \\\n",
       "count  ... 9641.00000 9641.00000 9641.00000 9641.00000  9641.00000   \n",
       "mean   ...    0.00249    0.00425    0.01805    0.00197     0.01753   \n",
       "std    ...    0.04983    0.06508    0.13313    0.04435     0.13124   \n",
       "min    ...    0.00000    0.00000    0.00000    0.00000     0.00000   \n",
       "25%    ...    0.00000    0.00000    0.00000    0.00000     0.00000   \n",
       "50%    ...    0.00000    0.00000    0.00000    0.00000     0.00000   \n",
       "75%    ...    0.00000    0.00000    0.00000    0.00000     0.00000   \n",
       "max    ...    1.00000    1.00000    1.00000    1.00000     1.00000   \n",
       "\n",
       "       key2_Period  key2_Quote  key2_Semicolon  key2_Slash  key2_Space  \n",
       "count   9641.00000  9641.00000      9641.00000  9641.00000  9641.00000  \n",
       "mean       0.02323     0.00892         0.00311     0.00062     0.07748  \n",
       "std        0.15065     0.09403         0.05570     0.02494     0.26737  \n",
       "min        0.00000     0.00000         0.00000     0.00000     0.00000  \n",
       "25%        0.00000     0.00000         0.00000     0.00000     0.00000  \n",
       "50%        0.00000     0.00000         0.00000     0.00000     0.00000  \n",
       "75%        0.00000     0.00000         0.00000     0.00000     0.00000  \n",
       "max        1.00000     1.00000         1.00000     1.00000     1.00000  \n",
       "\n",
       "[8 rows x 98 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hold</th>\n",
       "      <th>interkey</th>\n",
       "      <th>true</th>\n",
       "      <th>key1_Backquote</th>\n",
       "      <th>key1_Backslash</th>\n",
       "      <th>key1_BracketLeft</th>\n",
       "      <th>key1_BracketRight</th>\n",
       "      <th>key1_Comma</th>\n",
       "      <th>key1_Digit0</th>\n",
       "      <th>key1_Digit1</th>\n",
       "      <th>...</th>\n",
       "      <th>key2_KeyW</th>\n",
       "      <th>key2_KeyX</th>\n",
       "      <th>key2_KeyY</th>\n",
       "      <th>key2_KeyZ</th>\n",
       "      <th>key2_Minus</th>\n",
       "      <th>key2_Period</th>\n",
       "      <th>key2_Quote</th>\n",
       "      <th>key2_Semicolon</th>\n",
       "      <th>key2_Slash</th>\n",
       "      <th>key2_Space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.00000</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79.00000</td>\n",
       "      <td>122.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>263.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88.00000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>79.00000</td>\n",
       "      <td>64.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>77.00000</td>\n",
       "      <td>163.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>102.00000</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>89.00000</td>\n",
       "      <td>241.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854</th>\n",
       "      <td>174.00000</td>\n",
       "      <td>-119.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9641 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hold   interkey  true  key1_Backquote  key1_Backslash  \\\n",
       "2      89.00000  198.00000   NaN               0               0   \n",
       "3      66.00000   29.00000   NaN               0               0   \n",
       "5      79.00000  122.00000   NaN               0               0   \n",
       "6      66.00000  263.00000   NaN               0               0   \n",
       "7      88.00000   11.00000   NaN               0               0   \n",
       "...         ...        ...   ...             ...             ...   \n",
       "12850  79.00000   64.00000   NaN               0               0   \n",
       "12851  77.00000  163.00000   NaN               0               0   \n",
       "12852 102.00000  120.00000   NaN               0               0   \n",
       "12853  89.00000  241.00000   NaN               0               0   \n",
       "12854 174.00000 -119.00000   NaN               0               0   \n",
       "\n",
       "       key1_BracketLeft  key1_BracketRight  key1_Comma  key1_Digit0  \\\n",
       "2                     0                  0           0            0   \n",
       "3                     0                  0           0            0   \n",
       "5                     0                  0           0            0   \n",
       "6                     0                  0           0            0   \n",
       "7                     0                  0           0            0   \n",
       "...                 ...                ...         ...          ...   \n",
       "12850                 0                  0           0            0   \n",
       "12851                 0                  0           0            0   \n",
       "12852                 0                  0           0            0   \n",
       "12853                 0                  0           0            0   \n",
       "12854                 0                  0           0            0   \n",
       "\n",
       "       key1_Digit1  ...  key2_KeyW  key2_KeyX  key2_KeyY  key2_KeyZ  \\\n",
       "2                0  ...          0          0          0          0   \n",
       "3                0  ...          0          0          0          0   \n",
       "5                0  ...          0          0          0          0   \n",
       "6                0  ...          0          0          0          0   \n",
       "7                0  ...          0          0          0          0   \n",
       "...            ...  ...        ...        ...        ...        ...   \n",
       "12850            0  ...          0          0          0          0   \n",
       "12851            0  ...          0          0          0          0   \n",
       "12852            0  ...          0          0          0          0   \n",
       "12853            0  ...          0          0          0          0   \n",
       "12854            0  ...          0          0          0          0   \n",
       "\n",
       "       key2_Minus  key2_Period  key2_Quote  key2_Semicolon  key2_Slash  \\\n",
       "2               0            0           0               0           0   \n",
       "3               0            0           0               0           0   \n",
       "5               0            0           0               0           0   \n",
       "6               0            0           0               0           0   \n",
       "7               0            0           0               0           0   \n",
       "...           ...          ...         ...             ...         ...   \n",
       "12850           0            0           0               0           0   \n",
       "12851           0            0           0               0           0   \n",
       "12852           0            0           0               0           0   \n",
       "12853           0            0           0               0           0   \n",
       "12854           0            0           0               0           0   \n",
       "\n",
       "       key2_Space  \n",
       "2               0  \n",
       "3               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "...           ...  \n",
       "12850           0  \n",
       "12851           0  \n",
       "12852           0  \n",
       "12853           0  \n",
       "12854           0  \n",
       "\n",
       "[9641 rows x 99 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lof  iforest     svm\n",
      "accuracy  0.79003  0.56460 0.70954\n",
      "precision 0.82343  0.58098 0.94556\n",
      "recall    0.79782  0.81078 0.51322\n",
      "auc       0.86044  0.53419 0.85261\n",
      "[[1170  330]\n",
      " [ 390 1539]] \n",
      "\n",
      "[[ 372 1128]\n",
      " [ 365 1564]] \n",
      "\n",
      "[[1443   57]\n",
      " [ 939  990]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "both_train, both_test = train_test_split(both1.copy(), test_size=0.2, random_state=42)\n",
    "both_test['true'] = 1\n",
    "both2['true'] = -1\n",
    "both_test = pd.concat([both_test, both2])\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.2, n_neighbors=6)\n",
    "iforest = IsolationForest(random_state=42, contamination=0.2, bootstrap=True)\n",
    "svm = OneClassSVM(nu=0.1, gamma=0.04)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = both_test['true']\n",
    "\n",
    "X_train = both_train\n",
    "X_test = both_test.drop(columns=['true'])\n",
    "# X_train = both_train[['hold', 'interkey']]\n",
    "# X_test = both_test[['hold', 'interkey']]\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lof  iforest     svm\n",
      "accuracy  0.68037  0.51094 0.80140\n",
      "precision 0.71261  0.53925 0.88806\n",
      "recall    0.72369  0.89736 0.74028\n",
      "auc       0.74540  0.53018 0.85390\n",
      "[[ 937  563]\n",
      " [ 533 1396]] \n",
      "\n",
      "[[  21 1479]\n",
      " [ 198 1731]] \n",
      "\n",
      "[[1320  180]\n",
      " [ 501 1428]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "both_train, both_test = train_test_split(both1.copy(), test_size=0.2, random_state=42)\n",
    "both_test['true'] = 1\n",
    "both2['true'] = -1\n",
    "both_test = pd.concat([both_test, both2])\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.3, n_neighbors=3)\n",
    "iforest = IsolationForest(random_state=42, contamination=0.1, bootstrap=True)\n",
    "svm = OneClassSVM(nu=0.1, gamma=0.05)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = both_test.true\n",
    "\n",
    "X_train = both_train[['hold', 'interkey']]\n",
    "X_test = both_test[['hold', 'interkey']]\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              lof  iforest     svm\n",
      "accuracy  0.93923  0.48456 0.69172\n",
      "precision 0.96996  0.53186 0.72603\n",
      "recall    0.92021  0.68062 0.72381\n",
      "auc       0.97396  0.55363 0.63664\n",
      "[[3437  130]\n",
      " [ 364 4198]] \n",
      "\n",
      "[[ 834 2733]\n",
      " [1457 3105]] \n",
      "\n",
      "[[2321 1246]\n",
      " [1260 3302]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "both_train, both_test = train_test_split(both1.copy(), test_size=0.2, random_state=42)\n",
    "both_test['true'] = 1\n",
    "both2['true'] = -1\n",
    "both_test = pd.concat([both_test, both2])\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.3, n_neighbors=2)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = both_test.true\n",
    "\n",
    "X_train = both_train[['delay']]\n",
    "X_test = both_test[['delay']]\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tab_count</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10285.000000</td>\n",
       "      <td>10285.000000</td>\n",
       "      <td>10285</td>\n",
       "      <td>10285</td>\n",
       "      <td>10285.000000</td>\n",
       "      <td>10285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5597.724259</td>\n",
       "      <td>1.309285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-03-28 03:03:25.856050944</td>\n",
       "      <td>4.966845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>374.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-02-20 19:27:31.911000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2977.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-03-16 17:27:31.696000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5592.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-03-31 09:48:07.003000064</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8247.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-11 10:56:43.508000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10818.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-20 21:21:53.288000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3031.144909</td>\n",
       "      <td>0.462221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.767710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       user_id                       url  \\\n",
       "count   10285.000000  10285.000000                     10285   \n",
       "unique           NaN           NaN                      6530   \n",
       "top              NaN           NaN  https://www.youtube.com/   \n",
       "freq             NaN           NaN                       358   \n",
       "mean     5597.724259      1.309285                       NaN   \n",
       "min       374.000000      1.000000                       NaN   \n",
       "25%      2977.000000      1.000000                       NaN   \n",
       "50%      5592.000000      1.000000                       NaN   \n",
       "75%      8247.000000      2.000000                       NaN   \n",
       "max     10818.000000      2.000000                       NaN   \n",
       "std      3031.144909      0.462221                       NaN   \n",
       "\n",
       "                            timestamp     tab_count   lang  \n",
       "count                           10285  10285.000000  10285  \n",
       "unique                            NaN           NaN      6  \n",
       "top                               NaN           NaN     en  \n",
       "freq                              NaN           NaN   5626  \n",
       "mean    2021-03-28 03:03:25.856050944      4.966845    NaN  \n",
       "min        2021-02-20 19:27:31.911000      1.000000    NaN  \n",
       "25%        2021-03-16 17:27:31.696000      3.000000    NaN  \n",
       "50%     2021-03-31 09:48:07.003000064      5.000000    NaN  \n",
       "75%        2021-04-11 10:56:43.508000      6.000000    NaN  \n",
       "max        2021-04-20 21:21:53.288000     21.000000    NaN  \n",
       "std                               NaN      2.767710    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df.timestamp.apply(datetime.isoweekday)\n",
    "df['hour'] = df['timestamp'].dt.hour + 1\n",
    "df.lang = df.lang.replace(['uk', ''], ['ua', 'und'])\n",
    "df.loc[:, 'lang'] = df.lang.map({'und': 1, 'ua': 2, 'ru': 3, 'en': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[['url', 'tab_count', 'lang', 'weekday', 'hour']].profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465.000226"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.438266*(596+465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.user_id == 1].copy()\n",
    "df2 = df[df.user_id == 2].copy().sample(frac=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7104, 8), (1113, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nourl = df[['user_id', 'tab_count', 'lang', 'weekday', 'hour']].copy()\n",
    "nourl.loc[:, 'lang'] = nourl.lang.map({'und': 1, 'ua': 2, 'ru': 3, 'en': 4})\n",
    "nourl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nourl.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nourl1 = nourl[nourl.user_id == 1]\n",
    "nourl2 = nourl[nourl.user_id == 2].sample(frac=0.35)\n",
    "nourl1 = nourl1.drop(columns=['user_id'])\n",
    "nourl2 = nourl2.drop(columns=['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nourl_train, nourl_test = train_test_split(nourl1.copy(), test_size=0.15, random_state=42)\n",
    "nourl_test['true'] = 1\n",
    "nourl2['true'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nourl_train.shape, nourl_test.shape, nourl2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tab_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10127</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.google.com/search?q=%D0%BF%D0%B5%D...</td>\n",
       "      <td>2021-04-19 06:59:33.862</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10128</td>\n",
       "      <td>2</td>\n",
       "      <td>https://pethouse.ua/</td>\n",
       "      <td>2021-04-19 06:59:42.925</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10131</td>\n",
       "      <td>2</td>\n",
       "      <td>https://pethouse.ua/shop/sobakam/igrushki/joys...</td>\n",
       "      <td>2021-04-19 07:03:01.192</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10133</td>\n",
       "      <td>2</td>\n",
       "      <td>https://pethouse.ua/shop/koshkam/napolniteli-d...</td>\n",
       "      <td>2021-04-19 07:04:20.867</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10134</td>\n",
       "      <td>2</td>\n",
       "      <td>https://pethouse.ua/shop/koshkam/napolniteli-d...</td>\n",
       "      <td>2021-04-19 07:04:25.009</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10280</th>\n",
       "      <td>10116</td>\n",
       "      <td>2</td>\n",
       "      <td>https://thejigsawpuzzles.com/Food-and-Bakery/A...</td>\n",
       "      <td>2021-04-18 21:52:52.829</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10281</th>\n",
       "      <td>10117</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/channel/UCgUlPeG3lQvla...</td>\n",
       "      <td>2021-04-18 22:05:53.800</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10282</th>\n",
       "      <td>10122</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=BHOkdt-UUeg</td>\n",
       "      <td>2021-04-18 22:17:17.026</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>10123</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=T-rhtd_WIaQ</td>\n",
       "      <td>2021-04-18 22:19:15.110</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10284</th>\n",
       "      <td>10125</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.youtube.com/watch?v=lwpaXUfcBok</td>\n",
       "      <td>2021-04-18 22:21:31.554</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10285 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id                                                url  \\\n",
       "0      10127        2  https://www.google.com/search?q=%D0%BF%D0%B5%D...   \n",
       "1      10128        2                               https://pethouse.ua/   \n",
       "2      10131        2  https://pethouse.ua/shop/sobakam/igrushki/joys...   \n",
       "3      10133        2  https://pethouse.ua/shop/koshkam/napolniteli-d...   \n",
       "4      10134        2  https://pethouse.ua/shop/koshkam/napolniteli-d...   \n",
       "...      ...      ...                                                ...   \n",
       "10280  10116        2  https://thejigsawpuzzles.com/Food-and-Bakery/A...   \n",
       "10281  10117        1  https://www.youtube.com/channel/UCgUlPeG3lQvla...   \n",
       "10282  10122        1        https://www.youtube.com/watch?v=BHOkdt-UUeg   \n",
       "10283  10123        1        https://www.youtube.com/watch?v=T-rhtd_WIaQ   \n",
       "10284  10125        1        https://www.youtube.com/watch?v=lwpaXUfcBok   \n",
       "\n",
       "                    timestamp  tab_count  lang  weekday  hour  \n",
       "0     2021-04-19 06:59:33.862          4     3        1     7  \n",
       "1     2021-04-19 06:59:42.925          4     3        1     7  \n",
       "2     2021-04-19 07:03:01.192          4     3        1     8  \n",
       "3     2021-04-19 07:04:20.867          4     3        1     8  \n",
       "4     2021-04-19 07:04:25.009          4     3        1     8  \n",
       "...                       ...        ...   ...      ...   ...  \n",
       "10280 2021-04-18 21:52:52.829          3     3        7    22  \n",
       "10281 2021-04-18 22:05:53.800          5     4        7    23  \n",
       "10282 2021-04-18 22:17:17.026          6     4        7    23  \n",
       "10283 2021-04-18 22:19:15.110          6     4        7    23  \n",
       "10284 2021-04-18 22:21:31.554          6     4        7    23  \n",
       "\n",
       "[10285 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('dataclips_vitlsnqrfxkmvlwbzhtqqxowespx (1).csv')\n",
    "df = df.iloc[4:, :]\n",
    "df = df[df.cpm < 6000]\n",
    "# df['weekday'] = df.timestamp.apply(datetime.isoweekday)\n",
    "# df['hour'] = df['timestamp'].dt.hour + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train, test, columns=None, true=None, cv=False, tfidf=False,\n",
    "          cv_analyzer='char', ngram=(5, 5), precision_recall=True):\n",
    "    train_new = train.copy()\n",
    "    test_new = test.copy()\n",
    "    res = pd.DataFrame()\n",
    "    if true is None:\n",
    "        true = test_new['true'].values\n",
    "    if columns is None:\n",
    "        columns = list(test.columns)\n",
    "    if cv:\n",
    "        cv = CountVectorizer(analyzer=cv_analyzer)\n",
    "        if cv_analyzer == 'char':\n",
    "            cv.ngram_range = ngram\n",
    "        train_new = cv.fit_transform(train_new[columns])\n",
    "        test_new = cv.transform(test_new[columns])\n",
    "        if tfidf:\n",
    "            tf = TfidfTransformer()\n",
    "            train_new = tf.fit_transform(train_new)\n",
    "            test_new = tf.transform(test_new)\n",
    "    lof = LocalOutlierFactor(novelty=True)\n",
    "    iforest = IsolationForest(random_state=42)\n",
    "    svm = OneClassSVM()\n",
    "    for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "        model[0].fit(train_new)\n",
    "        res[model[1]] = model[0].predict(test_new) if cv else model[0].predict(test_new[columns])\n",
    "        res[model[1] + '_df'] = model[0].decision_function(test_new) if cv else model[0].decision_function(test_new[columns])\n",
    "    res['true'] = true\n",
    "    print(f'LOF accuracy: \\t\\t{accuracy(res.true, res.lof)}\\n'\n",
    "          f'iForest accuracy: \\t{accuracy(res.true, res.iforest)}\\n'\n",
    "          f'SVM accuracy: \\t\\t{accuracy(res.true, res.svm)}\\n')\n",
    "    if precision_recall:\n",
    "        print(f'LOF precision: \\t\\t{precision(res.true, res.lof)}\\n'\n",
    "              f'iForest precision: \\t{precision(res.true, res.iforest)}\\n'\n",
    "              f'SVM precision: \\t\\t{precision(res.true, res.svm)}\\n\\n'\n",
    "              f'LOF recall: \\t\\t{recall(res.true, res.lof)}\\n'\n",
    "              f'iForest recall: \\t{recall(res.true, res.iforest)}\\n'\n",
    "              f'SVM recall: \\t\\t{recall(res.true, res.svm)}\\n\\n'\n",
    "              f'LOF auc: \\t\\t{auc(res.true, res.lof_df)}\\n'\n",
    "              f'iForest auc: \\t\\t{auc(res.true, res.iforest_df)}\\n'\n",
    "              f'SVM auc: \\t\\t{auc(res.true, res.svm_df)}\\n')\n",
    "    metrics = pd.DataFrame(\n",
    "        [\n",
    "            [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "            [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "            [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "            [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "        ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train(x_train, x_test1, ['tab_count', 'lang', 'weekday', 'hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train(x_train, nourl2, ['tab_count', 'lang', 'weekday', 'hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "nourl_res = train_models(nourl_train, pd.concat([nourl_test, nourl2]), ['tab_count', 'lang', 'weekday', 'hour'])\n",
    "with open(f'nourl{date.today()}.html', 'w') as f:\n",
    "    f.write(nourl_res.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = ['http', 'https', 'www', 'com', 'org', 'net', 'int', 'edu', 'gov', 'mil', '']\n",
    "DELIMITERS = ['&', '$', '+', ',', '/', ':', ';', '=', '?', '!', '@', '#', '-', '.', '_', '~', '%']\n",
    "PATTERN = '|'.join(map(re.escape, DELIMITERS))\n",
    "\n",
    "def process_url(url):\n",
    "    url = urlparse(url.lower())\n",
    "    url = url.netloc + url.path\n",
    "    url = re.split(PATTERN, url)\n",
    "    url = ''.join([word for word in url if word not in STOPWORDS])\n",
    "    #ngrams\n",
    "    n = 5\n",
    "    url = [url[i : i + n] for i in range(len(url) - n + 1)]\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "pipeline2 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', IsolationForest(random_state=42))\n",
    "])\n",
    "pipeline3 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneClassSVM())\n",
    "])\n",
    "pipeline4 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer=process_url)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "pipeline5 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer=process_url)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', IsolationForest(random_state=42))\n",
    "])\n",
    "pipeline6 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer=process_url)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneClassSVM())\n",
    "])\n",
    "pipeline7 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer='char', ngram_range=(5, 5))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "pipeline8 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer='char', ngram_range=(5, 5))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', IsolationForest(random_state=42))\n",
    "])\n",
    "pipeline9 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer='char', ngram_range=(5, 5))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneClassSVM())\n",
    "])\n",
    "\n",
    "pipeline11 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500)),\n",
    "    ('clf', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "pipeline21 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500)),\n",
    "    ('clf', IsolationForest(random_state=42))\n",
    "])\n",
    "pipeline31 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500)),\n",
    "    ('clf', OneClassSVM())\n",
    "])\n",
    "pipeline41 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer=process_url)),\n",
    "    ('clf', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "pipeline51 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer=process_url)),\n",
    "    ('clf', IsolationForest(random_state=42))\n",
    "])\n",
    "pipeline61 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer=process_url)),\n",
    "    ('clf', OneClassSVM())\n",
    "])\n",
    "pipeline71 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer='char', ngram_range=(5, 5))),\n",
    "    ('clf', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "pipeline81 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer='char', ngram_range=(5, 5))),\n",
    "    ('clf', IsolationForest(random_state=42))\n",
    "])\n",
    "pipeline91 = Pipeline([\n",
    "    ('cv', CountVectorizer(max_features=500, analyzer='char', ngram_range=(5, 5))),\n",
    "    ('clf', OneClassSVM())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv0 = CountVectorizer()\n",
    "cv1 = CountVectorizer(analyzer=process_url)\n",
    "cv2 = CountVectorizer(analyzer='char', ngram_range=(5, 5))\n",
    "tfidf = TfidfTransformer()\n",
    "lof = LocalOutlierFactor(novelty=True)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a1 = cv1.build_analyzer()\n",
    "a2 = cv2.build_analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url = df1.iloc[450].url\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a1(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url_train.shape, url_test.shape, df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = pd.concat([url_test, df2])\n",
    "res = pd.DataFrame()\n",
    "res['true'] = test['true']\n",
    "metrics = pd.DataFrame(index=range(1, 19), columns=['accuracy', 'precision', 'recall'])\n",
    "for i, pipe in enumerate(\n",
    "    [pipeline1, pipeline2, pipeline3, pipeline4, pipeline5, pipeline6, pipeline7, pipeline8, pipeline9,\n",
    "    pipeline11, pipeline21, pipeline31, pipeline41, pipeline51, pipeline61, pipeline71, pipeline81, pipeline91]):\n",
    "    pipe.fit(url_train.url)\n",
    "    res['pred'] = pipe.predict(test.url)\n",
    "    metrics.iloc[i, :] = [accuracy(res.true, res.pred), precision(res.true, res.pred), recall(res.true, res.pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iforest = IsolationForest(random_state=42)\n",
    "cv = CountVectorizer(analyzer=process_url, max_features=5000)\n",
    "test = pd.concat([url_test, df2])\n",
    "res = pd.DataFrame()\n",
    "res['true'] = test['true']\n",
    "train = cv.fit_transform(url_train.url)\n",
    "test = cv.transform(test.url)\n",
    "iforest.fit(train)\n",
    "res['pred'] = iforest.predict(test)\n",
    "print(accuracy(res.true, res.pred))\n",
    "print(precision(res.true, res.pred))\n",
    "print(recall(res.true, res.pred))\n",
    "print(confm(res.true, res.pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv.stop_words_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url_char = train(url_train, url_test, 'url', cv=True, tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train(url_train, df2, 'url', cv=True, tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train, url_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "url_test['true'] = 1\n",
    "df2['true'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF accuracy: \t\t0.49105094079853145\n",
      "iForest accuracy: \t0.48921523634694813\n",
      "SVM accuracy: \t\t0.7333639284075264\n",
      "\n",
      "LOF precision: \t\t0.4853242320819113\n",
      "iForest precision: \t0.48921523634694813\n",
      "SVM precision: \t\t0.8263795423956931\n",
      "\n",
      "LOF recall: \t\t0.6669793621013134\n",
      "iForest recall: \t1.0\n",
      "SVM recall: \t\t0.575984990619137\n",
      "\n",
      "LOF auc: \t\t0.620478348158974\n",
      "iForest auc: \t\t0.28730515534473194\n",
      "SVM auc: \t\t0.8138294823752716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_char_tf = train_models(url_train, pd.concat([url_test, df2]), 'url', cv=True, tfidf=True)\n",
    "with open(f'url_char_tf{date.today()}.html', 'w') as f:\n",
    "    f.write(url_char_tf.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF accuracy: \t\t0.6888480954566315\n",
      "iForest accuracy: \t0.48921523634694813\n",
      "SVM accuracy: \t\t0.45250114731528224\n",
      "\n",
      "LOF precision: \t\t0.7194570135746606\n",
      "iForest precision: \t0.48921523634694813\n",
      "SVM precision: \t\t0.455994455994456\n",
      "\n",
      "LOF recall: \t\t0.5966228893058161\n",
      "iForest recall: \t1.0\n",
      "SVM recall: \t\t0.6172607879924953\n",
      "\n",
      "LOF auc: \t\t0.6177382595928385\n",
      "iForest auc: \t\t0.36715079674122475\n",
      "SVM auc: \t\t0.36522110348617487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_char = train_models(url_train, pd.concat([url_test, df2]), 'url', cv=True)\n",
    "with open(f'url_char{date.today()}.html', 'w') as f:\n",
    "    f.write(url_char.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF accuracy: \t\t0.6200091785222579\n",
      "iForest accuracy: \t0.48921523634694813\n",
      "SVM accuracy: \t\t0.5557595227168426\n",
      "\n",
      "LOF precision: \t\t0.5670800450958287\n",
      "iForest precision: \t0.48921523634694813\n",
      "SVM precision: \t\t0.7355769230769231\n",
      "\n",
      "LOF recall: \t\t0.9437148217636022\n",
      "iForest recall: \t1.0\n",
      "SVM recall: \t\t0.14352720450281425\n",
      "\n",
      "LOF auc: \t\t0.8474981836693756\n",
      "iForest auc: \t\t0.20815654662870492\n",
      "SVM auc: \t\t0.8061233520276319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_custom_tf = train_models(url_train, pd.concat([url_test, df2]), 'url', cv=True, tfidf=True, cv_analyzer=process_url)\n",
    "with open(f'url_custom_ngram_tf{date.today()}.html', 'w') as f:\n",
    "    f.write(url_custom_tf.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF accuracy: \t\t0.7930243230839835\n",
      "iForest accuracy: \t0.48921523634694813\n",
      "SVM accuracy: \t\t0.31206975676916016\n",
      "\n",
      "LOF precision: \t\t0.8482446206115515\n",
      "iForest precision: \t0.48921523634694813\n",
      "SVM precision: \t\t0.2920268972142171\n",
      "\n",
      "LOF recall: \t\t0.702626641651032\n",
      "iForest recall: \t1.0\n",
      "SVM recall: \t\t0.2851782363977486\n",
      "\n",
      "LOF auc: \t\t0.7837441359070443\n",
      "iForest auc: \t\t0.21319760160073092\n",
      "SVM auc: \t\t0.2759815349553039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_custom = train_models(url_train, pd.concat([url_test, df2]), 'url', cv=True, cv_analyzer=process_url)\n",
    "with open(f'url_custom_ngram{date.today()}.html', 'w') as f:\n",
    "    f.write(url_custom.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.loc[:, 'lang'] = df.lang.map({'und': 1, 'ua': 2, 'ru': 3, 'en': 4})\n",
    "df1 = df[df.user_id == 1].copy()\n",
    "df2 = df[df.user_id == 2].copy().sample(frac=0.35)\n",
    "df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lof   iforest       svm\n",
      "accuracy   0.793942  0.759982  0.735659\n",
      "precision  0.858304  0.867388  0.757895\n",
      "recall     0.693246  0.601313  0.675422\n",
      "auc        0.809878  0.766038  0.793931\n",
      "[[991 122]\n",
      " [327 739]] \n",
      "\n",
      "[[1015   98]\n",
      " [ 425  641]] \n",
      "\n",
      "[[883 230]\n",
      " [346 720]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "df2['true'] = -1\n",
    "X_test = pd.concat([X_test, df2])\n",
    "# X_train.shape, X_test.shape, df2.shape\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.3)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "cv = CountVectorizer(analyzer=process_url, max_features=10)\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "# urls_train = cv.fit_transform(X_train.url)\n",
    "# urls_test = cv.transform(X_test.url)\n",
    "# urls_train = tf.fit_transform(urls_train)\n",
    "# urls_test = tf.transform(urls_test)\n",
    "# X_train = hstack([urls_train, csr_matrix(X_train[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "# X_test = hstack([urls_test, csr_matrix(X_test[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "\n",
    "X_train = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "X_test = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "\n",
    "lof.fit(X_train)\n",
    "iforest.fit(X_train)\n",
    "svm.fit(X_train)\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lof   iforest       svm\n",
      "accuracy   0.793024  0.489215  0.312070\n",
      "precision  0.848245  0.489215  0.292027\n",
      "recall     0.702627  1.000000  0.285178\n",
      "auc        0.783744  0.213198  0.275982\n",
      "[[979 134]\n",
      " [317 749]] \n",
      "\n",
      "[[   0 1113]\n",
      " [   0 1066]] \n",
      "\n",
      "[[376 737]\n",
      " [762 304]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "df2['true'] = -1\n",
    "X_test = pd.concat([X_test, df2]).copy()\n",
    "# X_train.shape, X_test.shape, df2.shape\n",
    "\n",
    "# lof = LocalOutlierFactor(novelty=True, contamination=0.5)\n",
    "# iforest = IsolationForest(random_state=42)\n",
    "# svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "# cv = CountVectorizer(analyzer=process_url, max_features=3)\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM()\n",
    "cv = CountVectorizer(analyzer=process_url)\n",
    "\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "X_train = cv.fit_transform(X_train.url)\n",
    "X_test = cv.transform(X_test.url)\n",
    "# urls_train = tf.fit_transform(urls_train)\n",
    "# urls_test = tf.transform(urls_test)\n",
    "# X_train = hstack([urls_train, csr_matrix(X_train[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "# X_test = hstack([urls_test, csr_matrix(X_test[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "\n",
    "# X_train = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "# X_test = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "\n",
    "lof.fit(X_train)\n",
    "iforest.fit(X_train)\n",
    "svm.fit(X_train)\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lof   iforest       svm\n",
      "accuracy   0.609454  0.489215  0.555760\n",
      "precision  0.561393  0.489215  0.735577\n",
      "recall     0.922139  1.000000  0.143527\n",
      "auc        0.836386  0.208157  0.806123\n",
      "[[345 768]\n",
      " [ 83 983]] \n",
      "\n",
      "[[   0 1113]\n",
      " [   0 1066]] \n",
      "\n",
      "[[1058   55]\n",
      " [ 913  153]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "df2['true'] = -1\n",
    "X_test = pd.concat([X_test, df2]).copy()\n",
    "# X_train.shape, X_test.shape, df2.shape\n",
    "\n",
    "# lof = LocalOutlierFactor(novelty=True, contamination=0.5)\n",
    "# iforest = IsolationForest(random_state=42)\n",
    "# svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "# cv = CountVectorizer(analyzer=process_url, max_features=3)\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM()\n",
    "cv = CountVectorizer(analyzer=process_url)\n",
    "\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "urls_train = cv.fit_transform(X_train.url)\n",
    "urls_test = cv.transform(X_test.url)\n",
    "X_train = tf.fit_transform(urls_train)\n",
    "X_test = tf.transform(urls_test)\n",
    "# X_train = hstack([urls_train, csr_matrix(X_train[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "# X_test = hstack([urls_test, csr_matrix(X_test[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "\n",
    "# X_train = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "# X_test = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "\n",
    "lof.fit(X_train)\n",
    "iforest.fit(X_train)\n",
    "svm.fit(X_train)\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lof   iforest       svm\n",
      "accuracy   0.704452  0.489215  0.704911\n",
      "precision  0.862543  0.489215  0.993007\n",
      "recall     0.470919  1.000000  0.399625\n",
      "auc        0.633633  0.188016  0.828720\n",
      "[[1033   80]\n",
      " [ 564  502]] \n",
      "\n",
      "[[   0 1113]\n",
      " [   0 1066]] \n",
      "\n",
      "[[1110    3]\n",
      " [ 640  426]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "df2['true'] = -1\n",
    "X_test = pd.concat([X_test, df2])\n",
    "# X_train.shape, X_test.shape, df2.shape\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.5)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM(nu=0.2, gamma=0.4)\n",
    "cv = CountVectorizer(analyzer=process_url)\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "urls_train = cv.fit_transform(X_train.url)\n",
    "urls_test = cv.transform(X_test.url)\n",
    "# urls_train = tf.fit_transform(urls_train)\n",
    "# urls_test = tf.transform(urls_test)\n",
    "X_train = hstack([urls_train, csr_matrix(X_train[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "X_test = hstack([urls_test, csr_matrix(X_test[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "\n",
    "# X_train = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "# X_test = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "\n",
    "lof.fit(X_train)\n",
    "iforest.fit(X_train)\n",
    "svm.fit(X_train)\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                lof   iforest       svm\n",
      "accuracy   0.766866  0.489215  0.715925\n",
      "precision  0.817768  0.489215  0.747508\n",
      "recall     0.673546  1.000000  0.633208\n",
      "auc        0.810817  0.167430  0.777174\n",
      "[[953 160]\n",
      " [348 718]] \n",
      "\n",
      "[[   0 1113]\n",
      " [   0 1066]] \n",
      "\n",
      "[[885 228]\n",
      " [391 675]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "df2['true'] = -1\n",
    "X_test = pd.concat([X_test, df2])\n",
    "# X_train.shape, X_test.shape, df2.shape\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True, contamination=0.3)\n",
    "iforest = IsolationForest(random_state=42)\n",
    "svm = OneClassSVM(nu=0.2, gamma=0.3)\n",
    "cv = CountVectorizer(analyzer=process_url)\n",
    "tf = TfidfTransformer()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "urls_train = cv.fit_transform(X_train.url)\n",
    "urls_test = cv.transform(X_test.url)\n",
    "urls_train = tf.fit_transform(urls_train)\n",
    "urls_test = tf.transform(urls_test)\n",
    "X_train = hstack([urls_train, csr_matrix(X_train[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "X_test = hstack([urls_test, csr_matrix(X_test[['tab_count', 'lang', 'weekday', 'hour']])])\n",
    "\n",
    "# X_train = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "# X_test = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "\n",
    "lof.fit(X_train)\n",
    "iforest.fit(X_train)\n",
    "svm.fit(X_train)\n",
    "\n",
    "for model in [(lof, 'lof'), (iforest, 'iforest'), (svm, 'svm')]:\n",
    "    model[0].fit(X_train)\n",
    "    res[model[1]] = model[0].predict(X_test)\n",
    "    res[model[1] + '_df'] = model[0].decision_function(X_test)\n",
    "\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof), accuracy(res.true, res.iforest), accuracy(res.true, res.svm)],\n",
    "        [precision(res.true, res.lof), precision(res.true, res.iforest), precision(res.true, res.svm)],\n",
    "        [recall(res.true, res.lof), recall(res.true, res.iforest), recall(res.true, res.svm)],\n",
    "        [auc(res.true, res.lof_df), auc(res.true, res.iforest_df), auc(res.true, res.svm_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof', 'iforest', 'svm'])\n",
    "print(metrics)\n",
    "print(confm(res.true, res.lof), '\\n')\n",
    "print(confm(res.true, res.iforest), '\\n')\n",
    "print(confm(res.true, res.svm), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fit_multiple_estimators(classifiers, X_list):\n",
    "\n",
    "    # Fit all estimators with their respective feature arrays\n",
    "    estimators_ = [clf.fit(X) for clf, X in zip([clf for _, clf in classifiers], X_list)]\n",
    "\n",
    "    return estimators_\n",
    "\n",
    "\n",
    "def predict_from_multiple_estimator(estimators, X_list):\n",
    "\n",
    "    # Predict 'soft' voting with probabilities\n",
    "    pred1 = np.asarray([clf.predict_proba(X) for clf, X in zip(estimators, X_list)])\n",
    "    pred2 = np.average(pred1, axis=0)\n",
    "    pred = np.argmax(pred2, axis=1)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lof = LocalOutlierFactor(novelty=True)\n",
    "bag = BaggingClassifier(base_estimator=lof, random_state=42)\n",
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "X_test = pd.concat([X_test, df2]).copy()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "cv = CountVectorizer(analyzer=process_url)\n",
    "X_train = cv.fit_transform(X_train.url)\n",
    "X_test = cv.transform(X_test.url)\n",
    "# X_train2 = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "# X_test2 = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "bag.fit(X_train, np.zeros(X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bag.predict(csr_matrix(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res.lof = bag.predict(X_test)\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        [accuracy(res.true, res.lof)],\n",
    "        [precision(res.true, res.lof)],\n",
    "        [recall(res.true, res.lof)],\n",
    "        [auc(res.true, res.lof_df)]\n",
    "    ], ['accuracy', 'precision', 'recall', 'auc'], ['lof'])\n",
    "print(metrics)\n",
    "print('\\n', confm(res.true, res.lof))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf = [\n",
    "    ('lof1', LocalOutlierFactor(novelty=True)),\n",
    "    ('lof2', LocalOutlierFactor(novelty=True, contamination=0.3))\n",
    "]\n",
    "\n",
    "X_train, X_test = train_test_split(df1.copy(), test_size=0.15, random_state=42)\n",
    "X_test['true'] = 1\n",
    "# df2['true'] = -1\n",
    "X_test = pd.concat([X_test, df2]).copy()\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['true'] = X_test.true\n",
    "\n",
    "cv = CountVectorizer(analyzer=process_url)\n",
    "\n",
    "X_train1 = cv.fit_transform(X_train.url)\n",
    "X_test1 = cv.transform(X_test.url)\n",
    "X_train2 = X_train[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "X_test2 = X_test[['tab_count', 'lang', 'weekday', 'hour']]\n",
    "\n",
    "fitted = fit_multiple_estimators(clf, [X_train1, X_train2])\n",
    "pred = predict_from_multiple_estimator(fitted, [X_test1, X_test2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
